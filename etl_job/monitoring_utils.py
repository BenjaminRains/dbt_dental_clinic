"""
ETL Monitoring and Alerting Utilities for Dental Clinic Pipeline
"""

import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
from sqlalchemy import text
from datetime import datetime, timedelta
from connection_factory import get_target_connection
import logging

logger = logging.getLogger(__name__)

def send_etl_alert(subject: str, message: str, alert_type: str = 'info'):
    """Send email alerts for ETL issues."""
    try:
        # Email configuration (set via environment variables)
        smtp_server = os.getenv('SMTP_SERVER', 'localhost')
        smtp_port = int(os.getenv('SMTP_PORT', '587'))
        email_user = os.getenv('EMAIL_USER')
        email_password = os.getenv('EMAIL_PASSWORD')
        alert_recipients = os.getenv('ALERT_RECIPIENTS', '').split(',')
        
        if not all([email_user, email_password, alert_recipients]):
            logger.warning("Email configuration incomplete, skipping alert")
            return
        
        # Create message
        msg = MimeMultipart()
        msg['From'] = email_user
        msg['To'] = ', '.join(alert_recipients)
        msg['Subject'] = f"[DENTAL ETL {alert_type.upper()}] {subject}"
        
        # HTML body with dental clinic context
        html_body = f"""
        <html>
        <body>
            <h2>Dental Clinic ETL Alert</h2>
            <p><strong>Alert Type:</strong> {alert_type.upper()}</p>
            <p><strong>Timestamp:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>Message:</strong></p>
            <pre>{message}</pre>
            
            <hr>
            <p><em>This alert was generated by the dental clinic ETL monitoring system.</em></p>
            <p><em>Please check the Airflow UI for detailed logs and task status.</em></p>
        </body>
        </html>
        """
        
        msg.attach(MimeText(html_body, 'html'))
        
        # Send email
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(email_user, email_password)
            server.send_message(msg)
            
        logger.info(f"Alert sent successfully: {subject}")
        
    except Exception as e:
        logger.error(f"Failed to send alert: {str(e)}")

def check_etl_health():
    """Comprehensive health check for ETL pipeline."""
    health_issues = []
    
    try:
        with get_target_connection().connect() as conn:
            # Check for tables that haven't been updated recently
            stale_check_query = text("""
                SELECT 
                    table_name,
                    last_modified,
                    EXTRACT(EPOCH FROM (NOW() - last_modified))/3600 as hours_since_update
                FROM etl_sync_status 
                WHERE last_modified < NOW() - INTERVAL '24 hours'
                AND sync_status = 'success'
                ORDER BY last_modified ASC
            """)
            
            stale_tables = conn.execute(stale_check_query).fetchall()
            if stale_tables:
                stale_list = [f"{row[0]} ({row[2]:.1f}h ago)" for row in stale_tables]
                health_issues.append(f"Stale tables detected: {', '.join(stale_list)}")
            
            # Check for failed syncs in last 24 hours
            failed_sync_query = text("""
                SELECT table_name, last_modified, sync_status
                FROM etl_sync_status 
                WHERE sync_status != 'success'
                AND last_modified > NOW() - INTERVAL '24 hours'
            """)
            
            failed_syncs = conn.execute(failed_sync_query).fetchall()
            if failed_syncs:
                failed_list = [f"{row[0]} ({row[2]})" for row in failed_syncs]
                health_issues.append(f"Failed syncs: {', '.join(failed_list)}")
            
            # Check data freshness for critical tables
            critical_tables = ['appointment', 'procedurelog', 'payment']
            for table in critical_tables:
                freshness_query = text(f"""
                    SELECT MAX(_loaded_at) as last_load
                    FROM {table}
                    WHERE _loaded_at IS NOT NULL
                """)
                
                try:
                    result = conn.execute(freshness_query).scalar()
                    if result:
                        hours_old = (datetime.now() - result).total_seconds() / 3600
                        if hours_old > 6:  # Critical tables should be updated every 6 hours
                            health_issues.append(f"Critical table {table} is {hours_old:.1f} hours old")
                except Exception as e:
                    health_issues.append(f"Could not check freshness for {table}: {str(e)}")
            
            # Check for data quality issues
            quality_checks = {
                'appointment': "SELECT COUNT(*) FROM appointment WHERE AptDateTime IS NULL",
                'patient': "SELECT COUNT(*) FROM patient WHERE PatNum IS NULL OR LName = ''",
                'procedurelog': "SELECT COUNT(*) FROM procedurelog WHERE ProcDate IS NULL"
            }
            
            for table, check_query in quality_checks.items():
                try:
                    issue_count = conn.execute(text(check_query)).scalar()
                    if issue_count > 0:
                        health_issues.append(f"Data quality issue in {table}: {issue_count} problematic records")
                except Exception as e:
                    logger.warning(f"Could not run quality check for {table}: {str(e)}")
    
    except Exception as e:
        health_issues.append(f"Health check database error: {str(e)}")
    
    # Generate health report
    if health_issues:
        message = "ETL Health Check - Issues Detected:\n\n" + "\n".join([f"• {issue}" for issue in health_issues])
        send_etl_alert("ETL Health Issues Detected", message, "warning")
        return False
    else:
        logger.info("ETL health check passed - all systems normal")
        return True

def generate_etl_summary_report(**context):
    """Generate daily ETL summary report."""
    try:
        execution_date = context['execution_date']
        report_date = execution_date.strftime('%Y-%m-%d')
        
        with get_target_connection().connect() as conn:
            # Get sync statistics for the day
            summary_query = text("""
                SELECT 
                    table_name,
                    sync_status,
                    rows_processed,
                    last_modified
                FROM etl_sync_status 
                WHERE DATE(last_modified) = :report_date
                ORDER BY last_modified DESC
            """)
            
            results = conn.execute(summary_query.bindparams(report_date=report_date)).fetchall()
            
            if not results:
                message = f"No ETL activity recorded for {report_date}"
            else:
                # Format summary
                successful_syncs = [r for r in results if r[1] == 'success']
                failed_syncs = [r for r in results if r[1] != 'success']
                total_rows = sum(r[2] or 0 for r in successful_syncs)
                
                message = f"""
ETL Summary Report for {report_date}

OVERVIEW:
• Total tables processed: {len(results)}
• Successful syncs: {len(successful_syncs)}
• Failed syncs: {len(failed_syncs)}
• Total rows processed: {total_rows:,}

SUCCESSFUL SYNCS:
"""
                for result in successful_syncs:
                    message += f"• {result[0]}: {result[2]:,} rows at {result[3]}\n"
                
                if failed_syncs:
                    message += "\nFAILED SYNCS:\n"
                    for result in failed_syncs:
                        message += f"• {result[0]}: {result[1]} at {result[3]}\n"
        
        # Send summary report
        send_etl_alert(f"Daily ETL Summary - {report_date}", message, "info")
        
    except Exception as e:
        error_msg = f"Failed to generate ETL summary report: {str(e)}"
        logger.error(error_msg)
        send_etl_alert("ETL Summary Report Failed", error_msg, "error")

def create_monitoring_tables():
    """Create monitoring tables if they don't exist."""
    try:
        with get_target_connection().connect() as conn:
            # Create ETL sync status table
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS etl_sync_status (
                    table_name VARCHAR(100) PRIMARY KEY,
                    last_modified TIMESTAMP NOT NULL,
                    sync_status VARCHAR(20) NOT NULL DEFAULT 'pending',
                    rows_processed INTEGER DEFAULT 0,
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            # Create ETL metrics table for historical tracking
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS etl_metrics (
                    id SERIAL PRIMARY KEY,
                    table_name VARCHAR(100) NOT NULL,
                    sync_date DATE NOT NULL,
                    rows_processed INTEGER DEFAULT 0,
                    processing_time_seconds INTEGER,
                    sync_status VARCHAR(20) NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            # Create index for performance
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_etl_metrics_table_date 
                ON etl_metrics(table_name, sync_date)
            """))
            
            conn.commit()
            logger.info("Monitoring tables created/verified successfully")
            
    except Exception as e:
        logger.error(f"Failed to create monitoring tables: {str(e)}")
        raise