# ETL Pipeline Test Refactoring Plan

## Current State Issues
- Integration tests are heavily over-mocked
- They're actually unit tests in disguise
- No real integration testing happening
- Maintenance overhead is high

## Recommended Structure

### 1. Pure Unit Tests (`test_*_unit.py`)
```
tests/unit/
â”œâ”€â”€ test_pipeline_orchestrator_unit.py
â”œâ”€â”€ test_table_processor_unit.py
â”œâ”€â”€ test_priority_processor_unit.py
â””â”€â”€ test_postgres_loader_unit.py
```

**Characteristics:**
- âœ… Mock everything external
- âœ… Test specific logic paths
- âœ… Fast execution (< 1 second)
- âœ… No database dependencies

### 2. Integration Tests (`test_*_integration.py`)
```
tests/integration/
â”œâ”€â”€ test_pipeline_orchestrator_integration.py
â”œâ”€â”€ test_table_processor_integration.py
â””â”€â”€ test_etl_flow_integration.py
```

**Characteristics:**
- âœ… Real SQLite databases
- âœ… Real component interactions
- âœ… Minimal mocking (only external connections)
- âœ… Verify actual data flow
- â±ï¸ Medium execution (< 10 seconds)

### 3. End-to-End Tests (`test_*_e2e.py`)
```
tests/e2e/
â”œâ”€â”€ test_full_pipeline_e2e.py
â””â”€â”€ test_production_scenarios_e2e.py
```

**Characteristics:**
- âœ… Real MySQL/PostgreSQL in Docker
- âœ… No mocking
- âœ… Production-like scenarios
- â±ï¸ Slow execution (30+ seconds)
- ðŸ³ Requires Docker

## Migration Strategy

### Phase 1: Cleanup Current Tests
1. **Keep current tests as unit tests**
   - Move to `tests/unit/`
   - Keep all the mocking
   - These are actually good unit tests

2. **Remove "integration" markers**
   - Current tests are unit tests
   - Remove `@pytest.mark.integration`

### Phase 2: Add Real Integration Tests
1. **Create SQLite-based integration tests**
   - Use real TableProcessor
   - Use real PostgresLoader  
   - Use real SchemaDiscovery
   - Only mock ConnectionFactory

2. **Test actual data flow**
   ```python
   def test_patient_data_flow(self, sqlite_env):
       # Real processing
       processor = TableProcessor()
       result = processor.process_table('patient')
       
       # Verify real data movement
       assert data_in_replication_db()
       assert data_in_analytics_db()
       assert transformations_applied()
   ```

### Phase 3: Add E2E Tests
1. **Docker-based databases**
2. **Production-like scenarios**
3. **Full pipeline testing**

## Implementation Priority

### High Priority (Do First)
- [ ] Move current tests to `tests/unit/`
- [ ] Create 2-3 real integration tests with SQLite
- [ ] Test actual TableProcessor â†’ PostgresLoader flow

### Medium Priority
- [ ] Add Docker-based E2E tests
- [ ] Performance testing with large datasets
- [ ] Error recovery scenarios

### Low Priority
- [ ] Full production scenario testing
- [ ] Load testing
- [ ] Chaos engineering

## Benefits of This Approach

### Unit Tests
- Fast feedback during development
- Test specific logic paths
- Easy to debug
- High code coverage

### Integration Tests  
- Verify components work together
- Catch integration bugs
- Test real data transformations
- Reasonable execution time

### E2E Tests
- Production confidence
- Catch environment issues
- Full system validation
- Realistic performance testing

## Example Test Run Strategy

### Development (Fast Feedback)
```bash
pytest tests/unit/  # < 5 seconds
```

### CI/CD Pipeline
```bash
pytest tests/unit/ tests/integration/  # < 30 seconds
```

### Nightly/Release
```bash
pytest tests/  # All tests including E2E
```

## Key Principles

1. **Test the Right Thing at the Right Level**
   - Unit: Logic and algorithms
   - Integration: Component interactions
   - E2E: Full system behavior

2. **Minimize Mocking at Integration Level**
   - Only mock external dependencies
   - Let real components interact

3. **Use Real Data**
   - SQLite for integration tests
   - Docker databases for E2E
   - Realistic test datasets

4. **Optimize for Feedback Speed**
   - Fast unit tests for development
   - Medium integration tests for CI
   - Slow E2E tests for releases