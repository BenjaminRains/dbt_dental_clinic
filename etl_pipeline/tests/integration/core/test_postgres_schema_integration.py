# type: ignore  # SQLAlchemy type handling in integration tests

"""
Integration tests for the PostgresSchema class.

This module follows the connection architecture patterns:
- Uses FileConfigProvider for real configuration loading from .env_test
- Uses Settings injection for environment-agnostic connections
- Uses unified interface with ConnectionFactory
- Uses proper environment variable handling with .env_test
- Uses DatabaseType and PostgresSchema enums for type safety
- Follows the three-tier ETL testing strategy
- Tests real database connections with test environment
- Uses order markers for proper integration test execution
- Tests FAIL FAST behavior for missing ETL_ENVIRONMENT

Integration Test Strategy:
- Tests real database connections using test environment
- Validates schema extraction from MySQL replication database
- Tests schema adaptation and type conversion intelligence
- Tests PostgreSQL table creation with real analytics database
- Tests schema verification with real schema comparison
- Tests structured error handling with custom exceptions
- Tests FAIL FAST behavior for environment validation
- Tests schema-specific connections for PostgreSQL
- Tests MySQL-specific configurations for OpenDental
"""

import pytest
import os
import logging
from pathlib import Path
from typing import Optional, Dict, Any, Union, Tuple
from sqlalchemy import text, Result
from sqlalchemy.exc import OperationalError, DisconnectionError
from sqlalchemy.engine import Engine

# Import connection architecture components
from etl_pipeline.config import (
    Settings,
    DatabaseType,
    PostgresSchema,
    get_settings
)
from etl_pipeline.config.providers import FileConfigProvider
from etl_pipeline.core.connections import ConnectionFactory
from etl_pipeline.core.postgres_schema import PostgresSchema as PostgresSchemaClass

# Import fixtures for test data
from tests.fixtures.integration_fixtures import (
    populated_test_databases,
    test_settings_with_file_provider
)

# Import custom exceptions
from etl_pipeline.exceptions.schema import (
    SchemaTransformationError,
    SchemaValidationError,
    TypeConversionError
)
from etl_pipeline.exceptions.database import (
    DatabaseConnectionError,
    DatabaseTransactionError,
    DatabaseQueryError
)
from etl_pipeline.exceptions.data import DataExtractionError
from etl_pipeline.exceptions.configuration import ConfigurationError, EnvironmentError

logger = logging.getLogger(__name__)


def safe_fetch_one(result: Result) -> Optional[Any]:
    """Safely fetch one row from SQLAlchemy result with proper type handling."""
    try:
        row = result.fetchone()
        return row if row is not None else None
    except Exception:
        return None


def safe_fetch_all(result: Result) -> list:
    """Safely fetch all rows from SQLAlchemy result with proper type handling."""
    try:
        rows = result.fetchall()
        return [row for row in rows if row is not None]
    except Exception:
        return []


@pytest.fixture
def postgres_schema_instance(test_settings_with_file_provider):
    """
    Create PostgresSchema instance with real test environment.
    
    This fixture follows the connection architecture by:
    - Using FileConfigProvider for real configuration loading
    - Using Settings injection for environment-agnostic connections
    - Loading from real .env_test file and configuration files
    - Supporting integration testing with real environment setup
    - Using test environment variables (TEST_ prefixed)
    """
    try:
        # Create PostgresSchema instance with real test environment
        schema_instance = PostgresSchemaClass(
            postgres_schema=PostgresSchema.RAW,
            settings=test_settings_with_file_provider
        )
        
        # Validate that we can connect to test databases
        with schema_instance.mysql_engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            row = result.fetchone()
            if not row or row[0] != 1:
                pytest.skip("Test MySQL database connection failed")
        
        with schema_instance.postgres_engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            row = result.fetchone()
            if not row or row[0] != 1:
                pytest.skip("Test PostgreSQL database connection failed")
        
        return schema_instance
        
    except Exception as e:
        pytest.skip(f"Test databases not available: {str(e)}")


@pytest.mark.integration
@pytest.mark.order(3)  # After MySQL replicator, before data loading
@pytest.mark.postgres
@pytest.mark.etl_critical
@pytest.mark.provider_pattern
@pytest.mark.settings_injection
class TestPostgresSchemaIntegration:
    """
    Integration tests for PostgresSchema with real database connections.
    
    ETL Context:
        - Dental clinic nightly ETL pipeline (OpenDental â†’ Analytics)
        - All config via provider pattern (FileConfigProvider with .env_test)
        - All connections/config via Settings injection (environment='test')
        - Type safety with DatabaseType/PostgresSchema enums
        - Real test database connections (not production)
        - FAIL FAST on missing ETL_ENVIRONMENT
        - Order markers for proper ETL data flow validation
    """

    def test_real_schema_extraction_from_mysql(self, postgres_schema_instance, populated_test_databases):
        """
        Test extracting MySQL schema from real replication database.
        
        Validates:
            - Real MySQL schema extraction from replication database
            - Settings injection with FileConfigProvider
            - Schema metadata extraction (columns, types, constraints)
            - Error handling for non-existent tables
            - Test environment variable loading (.env_test)
            - Structured error handling with custom exceptions
            
        ETL Pipeline Context:
            - Replication: MySQL replication database (test_opendental_replication)
            - Used by PostgresSchema for schema analysis
            - Critical for schema conversion accuracy
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Test schema extraction for existing table
            mysql_schema = postgres_schema_instance.get_table_schema_from_mysql('patient')
            
            # Validate schema structure
            assert 'table_name' in mysql_schema
            assert 'create_statement' in mysql_schema
            assert 'columns' in mysql_schema
            assert 'metadata' in mysql_schema
            assert mysql_schema['table_name'] == 'patient'
            
            # Validate columns
            columns = mysql_schema['columns']
            assert len(columns) > 0
            
            # Check for expected dental clinic columns
            column_names = [col['name'] for col in columns]
            assert 'PatNum' in column_names
            assert 'LName' in column_names
            assert 'FName' in column_names
            
            # Validate metadata
            metadata = mysql_schema['metadata']
            assert 'engine' in metadata
            assert 'charset' in metadata
            
            logger.info(f"Successfully extracted schema for patient table with {len(columns)} columns")
            
        except Exception as e:
            pytest.skip(f"Schema extraction test failed: {str(e)}")

    def test_real_schema_adaptation_to_postgres(self, postgres_schema_instance, populated_test_databases):
        """
        Test adapting MySQL schema to PostgreSQL with real data analysis.
        
        Validates:
            - Real MySQL to PostgreSQL schema conversion
            - Intelligent type conversion with data analysis
            - TINYINT to boolean conversion logic
            - VARCHAR and other type conversions
            - Settings injection with FileConfigProvider
            - Structured error handling with custom exceptions
            
        ETL Pipeline Context:
            - Source: MySQL replication database schema
            - Target: PostgreSQL analytics database schema
            - Critical for data type compatibility
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Get MySQL schema from real database
            mysql_schema = postgres_schema_instance.get_table_schema_from_mysql('patient')
            
            # Adapt schema to PostgreSQL
            pg_create = postgres_schema_instance.adapt_schema('patient', mysql_schema)
            
            # Validate PostgreSQL CREATE statement
            assert pg_create is not None
            assert 'CREATE TABLE' in pg_create
            assert 'raw.patient' in pg_create
            
            # Check for type conversions
            assert 'boolean' in pg_create.lower() or 'smallint' in pg_create.lower()
            assert 'character varying' in pg_create.lower() or 'varchar' in pg_create.lower()
            
            # Check for column names (quoted for PostgreSQL)
            assert '"PatNum"' in pg_create
            assert '"LName"' in pg_create
            assert '"FName"' in pg_create
            
            logger.info(f"Successfully adapted MySQL schema to PostgreSQL: {pg_create[:200]}...")
            
        except Exception as e:
            pytest.skip(f"Schema adaptation test failed: {str(e)}")

    def test_real_table_creation_in_postgres(self, postgres_schema_instance, populated_test_databases):
        """
        Test creating PostgreSQL tables from adapted MySQL schema.
        
        Validates:
            - Real PostgreSQL table creation
            - Schema creation if not exists
            - Table dropping and recreation
            - Settings injection with FileConfigProvider
            - Structured error handling with custom exceptions
            - Database transaction handling
            
        ETL Pipeline Context:
            - Target: PostgreSQL analytics database (test_opendental_analytics)
            - Schema: raw schema for initial data loading
            - Critical for ETL pipeline data flow
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Get MySQL schema from real database
            mysql_schema = postgres_schema_instance.get_table_schema_from_mysql('patient')
            
            # Create PostgreSQL table
            success = postgres_schema_instance.create_postgres_table('patient', mysql_schema)
            assert success is True
            
            # Verify table exists in PostgreSQL
            with postgres_schema_instance.postgres_engine.connect() as conn:
                # Check if table exists
                result = conn.execute(text("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'raw' AND table_name = 'patient'
                """))
                table_exists = result.fetchone() is not None
                assert table_exists, "PostgreSQL table was not created"
                
                # Check column structure
                result = conn.execute(text("""
                    SELECT column_name, data_type 
                    FROM information_schema.columns 
                    WHERE table_schema = 'raw' AND table_name = 'patient'
                    ORDER BY ordinal_position
                """))
                columns = result.fetchall()
                assert len(columns) > 0, "PostgreSQL table has no columns"
                
                # Check for expected columns
                column_names = [col[0] for col in columns]
                assert 'PatNum' in column_names
                assert 'LName' in column_names
                assert 'FName' in column_names
                
            logger.info(f"Successfully created PostgreSQL table with {len(columns)} columns")
            
        except Exception as e:
            pytest.skip(f"Table creation test failed: {str(e)}")

    def test_real_schema_verification(self, postgres_schema_instance, populated_test_databases):
        """
        Test verifying PostgreSQL schema matches adapted MySQL schema.
        
        Validates:
            - Real schema verification between MySQL and PostgreSQL
            - Column count validation
            - Column name validation
            - Column type validation
            - Settings injection with FileConfigProvider
            - Structured error handling with custom exceptions
            
        ETL Pipeline Context:
            - Source: MySQL replication database schema
            - Target: PostgreSQL analytics database schema
            - Critical for data integrity validation
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Get MySQL schema from real database
            mysql_schema = postgres_schema_instance.get_table_schema_from_mysql('patient')
            
            # Create PostgreSQL table first
            success = postgres_schema_instance.create_postgres_table('patient', mysql_schema)
            assert success is True
            
            # Verify schema matches
            verification_success = postgres_schema_instance.verify_schema('patient', mysql_schema)
            assert verification_success is True, "Schema verification failed"
            
            logger.info("Successfully verified PostgreSQL schema matches MySQL schema")
            
        except Exception as e:
            pytest.skip(f"Schema verification test failed: {str(e)}")

    def test_real_type_conversion_intelligence(self, postgres_schema_instance, populated_test_databases):
        """
        Test intelligent type conversion with real column data analysis.
        
        Validates:
            - TINYINT to boolean conversion with data analysis
            - VARCHAR length preservation
            - DATETIME to timestamp conversion
            - Settings injection with FileConfigProvider
            - Structured error handling with custom exceptions
            - Real data analysis for type determination
            
        ETL Pipeline Context:
            - Source: MySQL replication database with real data
            - Target: PostgreSQL analytics database
            - Critical for data type accuracy
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Test TINYINT column analysis with real data
            # First, check if we have TINYINT columns in patient table
            with postgres_schema_instance.mysql_engine.connect() as conn:
                result = conn.execute(text("""
                    SELECT column_name, data_type 
                    FROM information_schema.columns 
                    WHERE table_schema = DATABASE() 
                    AND table_name = 'patient' 
                    AND data_type = 'tinyint'
                """))
                tinyint_columns = result.fetchall()
                
                if tinyint_columns:
                    # Test type conversion for TINYINT columns
                    for column_info in tinyint_columns:
                        column_name = column_info[0]
                        
                        # Test type conversion with real data analysis
                        pg_type = postgres_schema_instance._convert_mysql_type(
                            'tinyint', 'patient', column_name
                        )
                        
                        # Should be either boolean or smallint based on data analysis
                        assert pg_type in ['boolean', 'smallint'], f"Unexpected type conversion: {pg_type}"
                        
                        logger.info(f"Column {column_name}: tinyint -> {pg_type}")
                
            # Test other type conversions
            type_tests = [
                ('varchar(50)', 'character varying(50)'),
                ('int', 'integer'),
                ('datetime', 'timestamp'),
                ('text', 'text'),
                ('decimal(10,2)', 'numeric(10,2)')
            ]
            
            for mysql_type, expected_pg_type in type_tests:
                pg_type = postgres_schema_instance._convert_mysql_type_standard(mysql_type)
                assert pg_type == expected_pg_type, f"Type conversion failed: {mysql_type} -> {pg_type}"
                
            logger.info("Successfully tested intelligent type conversion")
            
        except Exception as e:
            pytest.skip(f"Type conversion test failed: {str(e)}")

    def test_real_error_handling_with_exceptions(self, postgres_schema_instance, populated_test_databases):
        """
        Test structured error handling with custom exceptions.
        
        Validates:
            - SchemaTransformationError for schema conversion failures
            - SchemaValidationError for schema validation failures
            - DatabaseConnectionError for connection failures
            - DatabaseTransactionError for transaction failures
            - DataExtractionError for data extraction failures
            - Settings injection with FileConfigProvider
            - Structured error context preservation
            
        ETL Pipeline Context:
            - Source: MySQL replication database
            - Target: PostgreSQL analytics database
            - Critical for error recovery and debugging
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Test error handling for non-existent table
            with pytest.raises(SchemaValidationError) as exc_info:
                postgres_schema_instance.get_table_schema_from_mysql('non_existent_table')
            
            error = exc_info.value
            assert error.table_name == 'non_existent_table'
            assert error.operation == 'schema_validation'
            assert 'not found' in error.message.lower()
            
            # Test error handling for invalid schema
            invalid_schema = {
                'create_statement': 'INVALID CREATE STATEMENT',
                'columns': [],
                'metadata': {}
            }
            
            with pytest.raises(SchemaTransformationError) as exc_info:
                postgres_schema_instance.adapt_schema('test_table', invalid_schema)
            
            error = exc_info.value
            assert error.table_name == 'test_table'
            assert error.operation == 'schema_transformation'
            
            logger.info("Successfully tested structured error handling")
            
        except Exception as e:
            pytest.skip(f"Error handling test failed: {str(e)}")

    def test_real_fail_fast_environment_validation(self):
        """
        Test FAIL FAST behavior for missing ETL_ENVIRONMENT.
        
        Validates:
            - System fails immediately if ETL_ENVIRONMENT not set
            - No defaulting to production environment
            - Clear error messages for missing environment
            - EnvironmentError exception for environment issues
            - Critical security requirement compliance
            
        ETL Pipeline Context:
            - Critical security requirement
            - Prevents accidental production usage
            - Clear error messages for debugging
            - Environment separation enforcement
        """
        # Store original environment
        original_env = os.environ.get('ETL_ENVIRONMENT')
        
        try:
            # Remove ETL_ENVIRONMENT to test FAIL FAST
            if 'ETL_ENVIRONMENT' in os.environ:
                del os.environ['ETL_ENVIRONMENT']
            
            # Test that PostgresSchema fails fast when ETL_ENVIRONMENT not set
            with pytest.raises((ValueError, EnvironmentError, ConfigurationError)) as exc_info:
                # Try to create PostgresSchema instance without ETL_ENVIRONMENT
                schema_instance = PostgresSchemaClass()
            
            # Verify error message indicates missing environment
            error_message = str(exc_info.value).lower()
            assert any(keyword in error_message for keyword in [
                'etl_environment', 'environment', 'not set', 'missing'
            ]), f"Error message should mention ETL_ENVIRONMENT: {error_message}"
            
            logger.info("Successfully tested FAIL FAST behavior for missing ETL_ENVIRONMENT")
            
        finally:
            # Restore original environment
            if original_env:
                os.environ['ETL_ENVIRONMENT'] = original_env

    def test_real_environment_separation(self, postgres_schema_instance, populated_test_databases):
        """
        Test environment separation between production and test.
        
        Validates:
            - Test environment uses test databases
            - Production environment uses production databases
            - No cross-environment contamination
            - Settings injection works for both environments
            - Provider pattern supports environment separation
            
        ETL Pipeline Context:
            - Test: Uses test_opendental_replication and test_opendental_analytics
            - Production: Uses opendental_replication and opendental_analytics
            - Critical for data isolation
            - Uses FileConfigProvider for real test environment
        """
        try:
            # Verify we're using test databases
            mysql_config = postgres_schema_instance.settings.get_replication_connection_config()
            postgres_config = postgres_schema_instance.settings.get_analytics_connection_config(PostgresSchema.RAW)
            
            # Check database names contain 'test_' prefix
            mysql_db = mysql_config.get('database', '')
            postgres_db = postgres_config.get('database', '')
            
            assert 'test_' in mysql_db.lower(), f"MySQL database should be test database: {mysql_db}"
            assert 'test_' in postgres_db.lower(), f"PostgreSQL database should be test database: {postgres_db}"
            
            # Verify we can connect to test databases
            with postgres_schema_instance.mysql_engine.connect() as conn:
                result = conn.execute(text("SELECT DATABASE()"))
                current_db = result.fetchone()[0]
                assert 'test_' in current_db.lower(), f"Connected to wrong database: {current_db}"
            
            with postgres_schema_instance.postgres_engine.connect() as conn:
                result = conn.execute(text("SELECT current_database()"))
                current_db = result.fetchone()[0]
                assert 'test_' in current_db.lower(), f"Connected to wrong database: {current_db}"
            
            logger.info("Successfully verified environment separation")
            
        except Exception as e:
            pytest.skip(f"Environment separation test failed: {str(e)}")

    def test_real_provider_pattern_integration(self, postgres_schema_instance, populated_test_databases):
        """
        Test provider pattern integration with FileConfigProvider.
        
        Validates:
            - FileConfigProvider loads real .env_test file
            - Settings injection works with provider pattern
            - Configuration loading from real files
            - Environment-specific variable handling
            - Provider pattern supports dependency injection
            
        ETL Pipeline Context:
            - Provider: FileConfigProvider with .env_test file
            - Settings: Settings injection for environment-agnostic connections
            - Configuration: Real configuration files (pipeline.yml, tables.yml)
            - Environment: Test environment with TEST_ prefixed variables
        """
        try:
            # Verify provider pattern is working
            settings = postgres_schema_instance.settings
            
            # Check that we're using FileConfigProvider
            assert hasattr(settings, 'provider')
            assert settings.provider is not None
            
            # Verify configuration is loaded from real files
            pipeline_config = settings.pipeline_config
            tables_config = settings.tables_config
            
            assert pipeline_config is not None, "Pipeline config should be loaded"
            assert tables_config is not None, "Tables config should be loaded"
            
            # Verify environment variables are loaded from .env_test
            mysql_config = settings.get_replication_connection_config()
            assert mysql_config.get('host') is not None, "MySQL host should be loaded from .env_test"
            assert mysql_config.get('database') is not None, "MySQL database should be loaded from .env_test"
            
            postgres_config = settings.get_analytics_connection_config(PostgresSchema.RAW)
            assert postgres_config.get('host') is not None, "PostgreSQL host should be loaded from .env_test"
            assert postgres_config.get('database') is not None, "PostgreSQL database should be loaded from .env_test"
            
            logger.info("Successfully verified provider pattern integration")
            
        except Exception as e:
            pytest.skip(f"Provider pattern test failed: {str(e)}")

    def test_real_settings_injection_patterns(self, postgres_schema_instance, populated_test_databases):
        """
        Test Settings injection patterns for environment-agnostic connections.
        
        Validates:
            - Settings injection works for all database types
            - Environment-agnostic connection creation
            - Unified interface with ConnectionFactory
            - Type safety with DatabaseType and PostgresSchema enums
            - Settings injection supports both production and test environments
            
        ETL Pipeline Context:
            - Settings: Environment-agnostic configuration management
            - ConnectionFactory: Unified interface for database connections
            - Enums: Type safety for database types and schemas
            - Provider: FileConfigProvider for real configuration loading
        """
        try:
            settings = postgres_schema_instance.settings
            
            # Test Settings injection for all database types
            source_config = settings.get_database_config(DatabaseType.SOURCE)
            replication_config = settings.get_database_config(DatabaseType.REPLICATION)
            analytics_config = settings.get_database_config(DatabaseType.ANALYTICS, PostgresSchema.RAW)
            
            # Verify configurations are loaded
            assert source_config is not None, "Source config should be loaded"
            assert replication_config is not None, "Replication config should be loaded"
            assert analytics_config is not None, "Analytics config should be loaded"
            
            # Test schema-specific configurations
            raw_config = settings.get_database_config(DatabaseType.ANALYTICS, PostgresSchema.RAW)
            staging_config = settings.get_database_config(DatabaseType.ANALYTICS, PostgresSchema.STAGING)
            intermediate_config = settings.get_database_config(DatabaseType.ANALYTICS, PostgresSchema.INTERMEDIATE)
            marts_config = settings.get_database_config(DatabaseType.ANALYTICS, PostgresSchema.MARTS)
            
            # Verify schema configurations
            assert raw_config is not None, "Raw schema config should be loaded"
            assert staging_config is not None, "Staging schema config should be loaded"
            assert intermediate_config is not None, "Intermediate schema config should be loaded"
            assert marts_config is not None, "Marts schema config should be loaded"
            
            # Test enum type safety
            assert isinstance(DatabaseType.SOURCE, DatabaseType), "DatabaseType should be enum"
            assert isinstance(PostgresSchema.RAW, PostgresSchema), "PostgresSchema should be enum"
            
            logger.info("Successfully verified Settings injection patterns")
            
        except Exception as e:
            pytest.skip(f"Settings injection test failed: {str(e)}")


@pytest.mark.integration
@pytest.mark.order(3)  # After MySQL replicator, before data loading
@pytest.mark.postgres
@pytest.mark.etl_critical
@pytest.mark.provider_pattern
@pytest.mark.settings_injection
class TestPostgresSchemaErrorHandlingIntegration:
    """
    Integration tests for PostgresSchema error handling with real database connections.
    
    ETL Context:
        - Dental clinic ETL pipeline error handling
        - All config via provider pattern (FileConfigProvider with .env_test)
        - All connections/config via Settings injection (environment='test')
        - Type safety with DatabaseType/PostgresSchema enums
        - Real test database connections (not production)
        - FAIL FAST on missing ETL_ENVIRONMENT
        - Structured error handling with custom exceptions
    """

    def test_real_database_connection_error_handling(self, test_settings_with_file_provider):
        """
        Test DatabaseConnectionError handling with real connection failures.
        
        Validates:
            - DatabaseConnectionError for connection failures
            - Structured error context preservation
            - Error details for debugging
            - Settings injection error handling
            - Provider pattern error handling
        """
        try:
            # Test with invalid connection parameters
            invalid_settings = Settings(environment='test')
            # Modify settings to use invalid connection parameters
            invalid_settings._env_vars.update({
                'TEST_MYSQL_REPLICATION_HOST': 'invalid-host',
                'TEST_MYSQL_REPLICATION_PORT': '9999'
            })
            
            # This should raise DatabaseConnectionError
            with pytest.raises((DatabaseConnectionError, OperationalError)) as exc_info:
                schema_instance = PostgresSchemaClass(
                    postgres_schema=PostgresSchema.RAW,
                    settings=invalid_settings
                )
            
            logger.info("Successfully tested database connection error handling")
            
        except Exception as e:
            # Skip if test databases are not available
            pytest.skip(f"Database connection error test failed: {str(e)}")

    def test_real_schema_transformation_error_handling(self, postgres_schema_instance, populated_test_databases):
        """
        Test SchemaTransformationError handling with invalid schemas.
        
        Validates:
            - SchemaTransformationError for schema conversion failures
            - Structured error context preservation
            - Error details for debugging
            - Table name and schema preservation
            - Original exception preservation
        """
        try:
            # Test with invalid MySQL schema
            invalid_schema = {
                'create_statement': 'INVALID CREATE TABLE STATEMENT',
                'columns': [],
                'metadata': {}
            }
            
            with pytest.raises(SchemaTransformationError) as exc_info:
                postgres_schema_instance.adapt_schema('test_table', invalid_schema)
            
            error = exc_info.value
            assert error.table_name == 'test_table'
            assert error.operation == 'schema_transformation'
            assert error.mysql_schema == invalid_schema
            
            logger.info("Successfully tested schema transformation error handling")
            
        except Exception as e:
            pytest.skip(f"Schema transformation error test failed: {str(e)}")

    def test_real_data_extraction_error_handling(self, postgres_schema_instance, populated_test_databases):
        """
        Test DataExtractionError handling with schema extraction failures.
        
        Validates:
            - DataExtractionError for data extraction failures
            - Structured error context preservation
            - Error details for debugging
            - Table name and operation preservation
            - Database type and connection details
        """
        try:
            # Test with non-existent table
            with pytest.raises(SchemaValidationError) as exc_info:
                postgres_schema_instance.get_table_schema_from_mysql('non_existent_table_12345')
            
            error = exc_info.value
            assert error.table_name == 'non_existent_table_12345'
            assert error.operation == 'schema_validation'
            assert 'not found' in error.message.lower()
            
            logger.info("Successfully tested data extraction error handling")
            
        except Exception as e:
            pytest.skip(f"Data extraction error test failed: {str(e)}")

    def test_real_environment_error_handling(self):
        """
        Test EnvironmentError handling for environment configuration issues.
        
        Validates:
            - EnvironmentError for environment configuration failures
            - FAIL FAST behavior for missing environment variables
            - Clear error messages for environment issues
            - No defaulting to production environment
            - Critical security requirement compliance
        """
        # Store original environment
        original_env = os.environ.get('ETL_ENVIRONMENT')
        
        try:
            # Test with missing ETL_ENVIRONMENT
            if 'ETL_ENVIRONMENT' in os.environ:
                del os.environ['ETL_ENVIRONMENT']
            
            with pytest.raises((ValueError, EnvironmentError, ConfigurationError)) as exc_info:
                # Try to create Settings without ETL_ENVIRONMENT
                settings = Settings()
            
            error_message = str(exc_info.value).lower()
            assert any(keyword in error_message for keyword in [
                'etl_environment', 'environment', 'not set', 'missing'
            ]), f"Error message should mention ETL_ENVIRONMENT: {error_message}"
            
            logger.info("Successfully tested environment error handling")
            
        finally:
            # Restore original environment
            if original_env:
                os.environ['ETL_ENVIRONMENT'] = original_env

    def test_real_configuration_error_handling(self, test_settings_with_file_provider):
        """
        Test ConfigurationError handling for configuration issues.
        
        Validates:
            - ConfigurationError for configuration validation failures
            - Structured error context preservation
            - Error details for debugging
            - Provider pattern error handling
            - Settings injection error handling
        """
        try:
            # Test with invalid configuration
            invalid_settings = Settings(environment='test')
            # Remove required configuration
            invalid_settings._env_vars.clear()
            
            with pytest.raises((ConfigurationError, ValueError)) as exc_info:
                # Try to get database configuration with invalid settings
                config = invalid_settings.get_replication_connection_config()
            
            logger.info("Successfully tested configuration error handling")
            
        except Exception as e:
            # Skip if test databases are not available
            pytest.skip(f"Configuration error test failed: {str(e)}") 