services:
  # Airflow Services
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
      - mysql
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DATABASE}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      # Nightly DAG at 9 PM Central (cron "0 21 * * *" interpreted in this timezone)
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=America/Chicago
      # ETL Connection Environment Variables
      - OPENDENTAL_SOURCE_USER=${OPENDENTAL_SOURCE_USER}
      - OPENDENTAL_SOURCE_PW=${OPENDENTAL_SOURCE_PW}
      - OPENDENTAL_SOURCE_HOST=${OPENDENTAL_SOURCE_HOST}
      - OPENDENTAL_SOURCE_PORT=${OPENDENTAL_SOURCE_PORT}
      - OPENDENTAL_SOURCE_DB=${OPENDENTAL_SOURCE_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DATABASE=${POSTGRES_DATABASE}
      # dbt analytics DB (same postgres for local; set POSTGRES_ANALYTICS_* in .env for EC2)
      - POSTGRES_ANALYTICS_HOST=${POSTGRES_ANALYTICS_HOST:-postgres}
      - POSTGRES_ANALYTICS_PORT=${POSTGRES_ANALYTICS_PORT:-5432}
      - POSTGRES_ANALYTICS_DB=${POSTGRES_ANALYTICS_DB:-${POSTGRES_DATABASE}}
      - POSTGRES_ANALYTICS_USER=${POSTGRES_ANALYTICS_USER:-${POSTGRES_USER}}
      - POSTGRES_ANALYTICS_PASSWORD=${POSTGRES_ANALYTICS_PASSWORD:-${POSTGRES_PASSWORD}}
      - POSTGRES_ANALYTICS_SCHEMA=${POSTGRES_ANALYTICS_SCHEMA:-public}
      # Email Configuration for Monitoring
      - SMTP_SERVER=${SMTP_SERVER:-localhost}
      - SMTP_PORT=${SMTP_PORT:-587}
      - EMAIL_USER=${EMAIL_USER}
      - EMAIL_PASSWORD=${EMAIL_PASSWORD}
      - ALERT_RECIPIENTS=${ALERT_RECIPIENTS}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/scripts:/opt/airflow/scripts
      - ./config:/opt/airflow/config
      - ./etl_job:/opt/airflow/dags/etl_job
      # Project root for ETL + dbt (nightly DAG)
      - ./etl_pipeline:/opt/airflow/dbt_dental_clinic/etl_pipeline
      - ./dbt_dental_models:/opt/airflow/dbt_dental_clinic/dbt_dental_models
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
      - mysql
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DATABASE}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=America/Chicago
      # ETL Connection Environment Variables (same as webserver)
      - OPENDENTAL_SOURCE_USER=${OPENDENTAL_SOURCE_USER}
      - OPENDENTAL_SOURCE_PW=${OPENDENTAL_SOURCE_PW}
      - OPENDENTAL_SOURCE_HOST=${OPENDENTAL_SOURCE_HOST}
      - OPENDENTAL_SOURCE_PORT=${OPENDENTAL_SOURCE_PORT}
      - OPENDENTAL_SOURCE_DB=${OPENDENTAL_SOURCE_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DATABASE=${POSTGRES_DATABASE}
      - POSTGRES_ANALYTICS_HOST=${POSTGRES_ANALYTICS_HOST:-postgres}
      - POSTGRES_ANALYTICS_PORT=${POSTGRES_ANALYTICS_PORT:-5432}
      - POSTGRES_ANALYTICS_DB=${POSTGRES_ANALYTICS_DB:-${POSTGRES_DATABASE}}
      - POSTGRES_ANALYTICS_USER=${POSTGRES_ANALYTICS_USER:-${POSTGRES_USER}}
      - POSTGRES_ANALYTICS_PASSWORD=${POSTGRES_ANALYTICS_PASSWORD:-${POSTGRES_PASSWORD}}
      - POSTGRES_ANALYTICS_SCHEMA=${POSTGRES_ANALYTICS_SCHEMA:-public}
      # Email Configuration for Monitoring
      - SMTP_SERVER=${SMTP_SERVER:-localhost}
      - SMTP_PORT=${SMTP_PORT:-587}
      - EMAIL_USER=${EMAIL_USER}
      - EMAIL_PASSWORD=${EMAIL_PASSWORD}
      - ALERT_RECIPIENTS=${ALERT_RECIPIENTS}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/scripts:/opt/airflow/scripts
      - ./config:/opt/airflow/config
      - ./etl_job:/opt/airflow/dags/etl_job
      - ./etl_pipeline:/opt/airflow/dbt_dental_clinic/etl_pipeline
      - ./dbt_dental_models:/opt/airflow/dbt_dental_clinic/dbt_dental_models
    command: scheduler

  # Airflow Init (run once to initialize database)
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DATABASE}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      # SECURITY: Airflow admin credentials from environment
      - AIRFLOW_ADMIN_USERNAME=${AIRFLOW_ADMIN_USERNAME}
      - AIRFLOW_ADMIN_PASSWORD=${AIRFLOW_ADMIN_PASSWORD}
      - AIRFLOW_ADMIN_EMAIL=${AIRFLOW_ADMIN_EMAIL:-admin@localhost}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: >
      bash -c "
        if [ -z \"$${AIRFLOW_ADMIN_PASSWORD}\" ]; then
          echo 'ERROR: AIRFLOW_ADMIN_PASSWORD not set. Refusing to create admin with default password.'
          exit 1
        fi
        airflow db init &&
        airflow users create \
          --username $${AIRFLOW_ADMIN_USERNAME} \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email $${AIRFLOW_ADMIN_EMAIL} \
          --password $${AIRFLOW_ADMIN_PASSWORD}
      "
    profiles:
      - init # Only run when specifically called

  # Existing dbt service
  dbt:
    build: .
    volumes:
      - .:/usr/app/dbt
      - ~/.dbt:/root/.dbt
    env_file:
      - .env
    environment:
      - DBT_PROFILES_DIR=/usr/app/dbt
      - DBT_PROJECT_DIR=/usr/app/dbt
    depends_on:
      - postgres
      - mysql
    command: dbt run
    profiles:
      - manual # Only run when specifically called

  # Database services
  postgres:
    image: postgres:18
    env_file:
      - .env
    # SECURITY: Ports removed - use Docker network for internal access
    # Uncomment ONLY for maintenance operations like pg_restore, then remove immediately:
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init:/docker-entrypoint-initdb.d # For initialization scripts
      - /usr/share/zoneinfo:/usr/share/zoneinfo:ro # Mount timezone data
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DATABASE}
      - POSTGRES_HOST_AUTH_METHOD=scram-sha-256 # Secure authentication
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DATABASE}" ]
      interval: 10s
      timeout: 5s
      retries: 5
    user: "999:999" # Run as postgres user (non-root)

  mysql:
    image: mysql:8.4
    env_file:
      - .env
    # Removed port exposure for security - access via Docker network only
    volumes:
      - mysql_data:/var/lib/mysql
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_ROOT_USER=${MYSQL_ROOT_USER}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost" ]
      interval: 10s
      timeout: 5s
      retries: 5
    user: "999:999" # Run as mysql user (non-root)

volumes:
  postgres_data:
  mysql_data:
