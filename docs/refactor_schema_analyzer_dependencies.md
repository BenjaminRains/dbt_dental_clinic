# Schema Analyzer Downstream Dependencies

**Document Purpose**: Identify all files that depend on `analyze_opendental_schema.py` to ensure safe refactoring.

**Script Location**: `etl_pipeline/scripts/analyze_opendental_schema.py`  
**Date**: 2025-01-17  
**Related Doc**: `docs/refactor_schema_analyzer_methods.md`

---

## Summary

‚úÖ **Good News**: The schema analyzer is a **standalone script** with minimal direct dependencies!

- **Direct Imports**: Only test files
- **Production Usage**: CLI calls it as a subprocess (loose coupling)
- **Data Consumer**: SimpleMySQLReplicator reads `tables.yml` (not the Python code)
- **Total Downstream Files**: 3 production files + 24 test files

---

## Production Code Dependencies

### 1. CLI Command (Subprocess Execution)

**File**: `etl_pipeline/etl_pipeline/cli/commands.py`  
**Lines**: 468-600 (`update_schema` command)  
**Usage**: Executes the script as a subprocess

```python
def update_schema(backup: bool, force: bool, output_dir: str, log_level: str):
    """Update ETL schema configuration by running analyze_opendental_schema.py."""
    
    # Get script path
    script_path = Path(__file__).parent.parent.parent / "scripts" / "analyze_opendental_schema.py"
    
    # Execute script (no direct import!)
    # Uses subprocess or direct execution
```

**Dependency Type**: ‚ö†Ô∏è **Loose Coupling** (subprocess)  
**Refactoring Impact**: ‚úÖ **NONE** - Script can be refactored freely  
**Why Safe**: CLI doesn't import methods, just executes the script

---

### 2. SimpleMySQLReplicator (Configuration Consumer)

**File**: `etl_pipeline/etl_pipeline/core/simple_mysql_replicator.py`  
**Lines**: Various (configuration reading)  
**Usage**: Reads `tables.yml` output file, NOT the Python code

```python
def _load_configuration(self) -> Dict:
    """Load table configuration from tables.yml."""
    with open(self.tables_config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    tables = config.get('tables', {})
    return tables

# Used in various methods
def calculate_adaptive_batch_size(self, table_name: str, config: Dict) -> int:
    config_batch_size = config.get('batch_size')  # From tables.yml
    incremental_columns = config.get('incremental_columns', [])  # From tables.yml
    # ...

def get_extraction_strategy(self, table_name: str) -> str:
    strategy = config.get('extraction_strategy', 'full_table')  # From tables.yml
    # ...
```

**Dependency Type**: üìÑ **Data Dependency** (reads YAML file)  
**Refactoring Impact**: ‚ö†Ô∏è **YAML FORMAT ONLY**  
**What to Preserve**: The structure of `tables.yml` output

#### Critical Fields Used by SimpleMySQLReplicator

```yaml
tables:
  patient:
    # CRITICAL - Used directly by replicator
    extraction_strategy: 'incremental'           # REQUIRED
    batch_size: 50000                           # REQUIRED
    incremental_columns: ['DateTStamp']         # REQUIRED
    primary_incremental_column: 'DateTStamp'    # REQUIRED
    
    # METADATA - Not used by replicator (safe to change)
    estimated_rows: 150000
    estimated_size_mb: 45.2
    performance_category: 'medium'
    processing_priority: 'high'
    time_gap_threshold_days: 30
    # ... other metadata
```

**Backward Compatibility Requirements**:
- ‚úÖ Keep these fields: `extraction_strategy`, `batch_size`, `incremental_columns`, `primary_incremental_column`
- ‚úÖ Can modify: All other metadata fields (safe to rename/add/remove)

---

### 3. PriorityProcessor (Indirect Consumer)

**File**: `etl_pipeline/etl_pipeline/orchestration/priority_processor.py`  
**Lines**: Various  
**Usage**: Processes tables based on configuration

```python
# PriorityProcessor uses TableProcessor which uses SimpleMySQLReplicator
# So it indirectly depends on tables.yml format
```

**Dependency Type**: üìÑ **Indirect Data Dependency**  
**Refactoring Impact**: ‚úÖ **NONE** - Uses same `tables.yml`

---

## Test Files (24 Total)

### Unit Tests (12 Files)

All import `OpenDentalSchemaAnalyzer` class directly:

```
etl_pipeline/tests/unit/scripts/analyze_opendental_schema/
‚îú‚îÄ‚îÄ test_batch_processing_unit.py
‚îú‚îÄ‚îÄ test_configuration_generation_unit.py
‚îú‚îÄ‚îÄ test_dbt_integration_unit.py
‚îú‚îÄ‚îÄ test_error_handling_unit.py
‚îú‚îÄ‚îÄ test_extraction_strategy_unit.py
‚îú‚îÄ‚îÄ test_importance_determination_unit.py
‚îú‚îÄ‚îÄ test_incremental_strategy_unit.py
‚îú‚îÄ‚îÄ test_initialization_unit.py
‚îú‚îÄ‚îÄ test_progress_monitoring_unit.py
‚îú‚îÄ‚îÄ test_schema_analysis_unit.py
‚îú‚îÄ‚îÄ test_size_analysis_unit.py
‚îî‚îÄ‚îÄ test_table_discovery_unit.py
```

**Import Pattern**:
```python
from scripts.analyze_opendental_schema import OpenDentalSchemaAnalyzer
```

**Refactoring Impact**: ‚ö†Ô∏è **HIGH** - Tests call methods directly  
**Action Required**: Update tests after refactoring

---

### Integration Tests (12 Files)

All import `OpenDentalSchemaAnalyzer` class:

```
etl_pipeline/tests/integration/scripts/analyze_opendental_schema/
‚îú‚îÄ‚îÄ test_batch_processing_integration.py
‚îú‚îÄ‚îÄ test_configuration_generation_integration.py
‚îú‚îÄ‚îÄ test_data_quality_integration.py
‚îú‚îÄ‚îÄ test_dbt_integration_integration.py
‚îú‚îÄ‚îÄ test_extraction_strategy_integration.py
‚îú‚îÄ‚îÄ test_incremental_strategy_integration.py
‚îú‚îÄ‚îÄ test_initialization_integration.py
‚îú‚îÄ‚îÄ test_performance_analysis_integration.py
‚îú‚îÄ‚îÄ test_reporting_integration.py
‚îú‚îÄ‚îÄ test_schema_analysis_integration.py
‚îú‚îÄ‚îÄ test_size_analysis_integration.py
‚îî‚îÄ‚îÄ test_table_discovery_integration.py
```

**Import Pattern**:
```python
from scripts.analyze_opendental_schema import OpenDentalSchemaAnalyzer
```

**Refactoring Impact**: ‚ö†Ô∏è **HIGH** - Tests call methods directly  
**Action Required**: Update tests after refactoring

---

## tables.yml Contract (Critical!)

This is the **only production interface** between the analyzer and the ETL pipeline.

### Required Fields (DO NOT REMOVE)

```yaml
# Top-level structure
metadata:
  generated_at: <ISO timestamp>
  analyzer_version: <string>
  source_database: <string>
  total_tables: <int>
  schema_hash: <string>

tables:
  <table_name>:
    # CRITICAL FIELDS (used by SimpleMySQLReplicator)
    extraction_strategy: 'full_table' | 'incremental' | 'incremental_chunked'
    batch_size: <int>
    incremental_columns: [<string>, ...]
    primary_incremental_column: <string>
    
    # METADATA FIELDS (not used by replicator, safe to change)
    estimated_rows: <int>
    estimated_size_mb: <float>
    performance_category: <string>
    processing_priority: <string>
    time_gap_threshold_days: <int>
    estimated_processing_time_minutes: <float>
    memory_requirements_mb: <int>
    monitoring: <dict>
    schema_hash: <int>
    last_analyzed: <ISO timestamp>
```

### Safe to Modify

These fields are NOT used by production code:
- ‚úÖ `estimated_rows` - Can rename/remove
- ‚úÖ `estimated_size_mb` - Can rename/remove
- ‚úÖ `performance_category` - Can rename/remove
- ‚úÖ `processing_priority` - Can rename/remove
- ‚úÖ `time_gap_threshold_days` - Can rename/remove
- ‚úÖ `estimated_processing_time_minutes` - Can rename/remove
- ‚úÖ `memory_requirements_mb` - Can rename/remove
- ‚úÖ `monitoring` - Can change structure
- ‚úÖ `schema_hash` - Can change
- ‚úÖ `last_analyzed` - Can change

### MUST Preserve

These fields ARE used by SimpleMySQLReplicator:
- ‚ùå `extraction_strategy` - **REQUIRED**, must be one of: `full_table`, `incremental`, `incremental_chunked`
- ‚ùå `batch_size` - **REQUIRED**, integer > 0
- ‚ùå `incremental_columns` - **REQUIRED**, list of strings (can be empty)
- ‚ùå `primary_incremental_column` - **REQUIRED**, string or null

---

## Refactoring Safety Checklist

### ‚úÖ Safe to Refactor (No Breaking Changes)

These changes won't affect production code:

- ‚úÖ **Method Consolidation**: Merge `get_estimated_row_count()` and `get_table_size_info()`
- ‚úÖ **Method Renaming**: Rename any method (tests will need updates)
- ‚úÖ **Method Deletion**: Remove unused methods
- ‚úÖ **Add New Methods**: Add helpers, utilities, etc.
- ‚úÖ **Change Internal Logic**: As long as `tables.yml` format stays the same
- ‚úÖ **Performance Optimization**: Database query consolidation, caching, etc.
- ‚úÖ **Documentation**: Improve docstrings, add comments
- ‚úÖ **Code Organization**: Reorder methods, add sections

### ‚ö†Ô∏è Requires Caution (Breaking Changes)

These changes need verification:

- ‚ö†Ô∏è **tables.yml Format**: Changing structure of critical fields
- ‚ö†Ô∏è **Script Entry Point**: Changing `main()` signature
- ‚ö†Ô∏è **Exit Codes**: CLI expects certain exit codes
- ‚ö†Ô∏è **Output Files**: CLI expects specific output files

### ‚ùå Not Safe (Will Break Production)

These changes WILL break production:

- ‚ùå **Remove `tables.yml` Output**: ETL pipeline depends on it
- ‚ùå **Change Critical Field Names**: `extraction_strategy`, `batch_size`, etc.
- ‚ùå **Change Field Types**: E.g., `batch_size` from int to string
- ‚ùå **Remove Script File**: CLI calls it by path

---

## Testing Requirements After Refactoring

### Phase 1: Unit Tests

```bash
# Run all analyzer unit tests
pytest etl_pipeline/tests/unit/scripts/analyze_opendental_schema/ -v

# Expected: Some tests will fail (need updates)
# Action: Update tests to match refactored methods
```

### Phase 2: Integration Tests

```bash
# Run all analyzer integration tests
pytest etl_pipeline/tests/integration/scripts/analyze_opendental_schema/ -v

# Expected: Some tests will fail (need updates)
# Action: Update tests to match refactored methods
```

### Phase 3: End-to-End Test

```bash
# 1. Run schema analyzer
python etl_pipeline/scripts/analyze_opendental_schema.py

# 2. Verify output
ls -la etl_pipeline/config/tables.yml

# 3. Verify format
python -c "import yaml; yaml.safe_load(open('etl_pipeline/config/tables.yml'))"

# 4. Test ETL pipeline can read config
etl run --tables patient --dry-run

# Expected: No errors, pipeline can parse tables.yml
```

### Phase 4: Replicator Integration Test

```bash
# Test that SimpleMySQLReplicator can read the new tables.yml
pytest etl_pipeline/tests/unit/core/simple_mysql_replicator/test_configuration_unit.py -v

# Expected: All tests pass (config format preserved)
```

---

## Method Call Analysis

### Methods Called by Tests (Need Updates)

Based on test files, these methods are called directly:

```python
# Discovery Methods
analyzer.discover_all_tables()
analyzer.discover_dbt_models()

# Schema Analysis
analyzer.get_table_schema(table_name)
analyzer.get_estimated_row_count(table_name)  # ‚ö†Ô∏è REFACTORING
analyzer.get_table_size_info(table_name)      # ‚ö†Ô∏è REFACTORING

# Incremental Loading
analyzer.find_incremental_columns(table_name, schema_info)
analyzer.validate_incremental_column_data_quality(table_name, column)
analyzer.select_primary_incremental_column(table_name, columns, schema)
analyzer.determine_incremental_strategy(table_name, schema, columns)
analyzer.determine_extraction_strategy(table_name, schema, size)  # ‚ö†Ô∏è REFACTORING

# Performance
analyzer.analyze_table_performance_characteristics(table_name, schema, size)  # ‚ö†Ô∏è RENAMING

# SCD Detection
analyzer.compare_with_previous_schema(config, previous_path)

# Batch Processing
analyzer.get_batch_schema_info(table_names)
analyzer.get_batch_size_info(table_names)

# Configuration
analyzer.generate_complete_configuration(output_dir)
analyzer.analyze_complete_schema(output_dir)
```

### Methods NOT Called by Tests (Safe to Delete)

```python
# These are only used internally, safe to refactor/delete
analyzer._generate_schema_hash()
analyzer._calculate_processing_priority()
analyzer._estimate_processing_time()
analyzer._estimate_memory_requirements()
analyzer._validate_extraction_strategy()
analyzer._generate_detailed_analysis_report()
analyzer._generate_performance_summary()
analyzer._generate_schema_changelog()
analyzer._get_batch_size_range()
```

---

## Refactoring Action Plan

### Step 1: Implement Phase 1 (Database Query Consolidation)

**Files to Change**:
- ‚úÖ `etl_pipeline/scripts/analyze_opendental_schema.py`

**Tests to Update**:
- ‚ö†Ô∏è `test_size_analysis_unit.py` - May need mock updates
- ‚ö†Ô∏è `test_size_analysis_integration.py` - Verify behavior unchanged

**Verification**:
```bash
# 1. Run analyzer
python etl_pipeline/scripts/analyze_opendental_schema.py

# 2. Compare tables.yml (should be identical)
diff etl_pipeline/config/tables.yml.backup etl_pipeline/config/tables.yml

# 3. Test ETL can read it
etl validate-config
```

---

### Step 2: Implement Phase 2 (Method Cleanup)

**Files to Change**:
- ‚úÖ `etl_pipeline/scripts/analyze_opendental_schema.py`

**Tests to Update**:
- ‚ö†Ô∏è `test_extraction_strategy_unit.py` - Update method calls
- ‚ö†Ô∏è `test_extraction_strategy_integration.py` - Update method calls

**Verification**:
```bash
pytest etl_pipeline/tests/unit/scripts/analyze_opendental_schema/test_extraction_strategy_unit.py -v
```

---

### Step 3: Implement Phase 3 (Naming Improvements)

**Files to Change**:
- ‚úÖ `etl_pipeline/scripts/analyze_opendental_schema.py`

**Tests to Update**:
- ‚ö†Ô∏è `test_performance_analysis_integration.py` - Update method name
- ‚ö†Ô∏è Any test calling `analyze_table_performance_characteristics()`

**Verification**:
```bash
grep -r "analyze_table_performance_characteristics" etl_pipeline/tests/
# Update all occurrences
```

---

### Step 4: Update All Tests

**Action**:
```bash
# Run all tests, fix failures one by one
pytest etl_pipeline/tests/unit/scripts/analyze_opendental_schema/ -v --tb=short
pytest etl_pipeline/tests/integration/scripts/analyze_opendental_schema/ -v --tb=short
```

---

### Step 5: Final Validation

**Checklist**:
- [ ] All unit tests pass
- [ ] All integration tests pass
- [ ] `tables.yml` format unchanged (critical fields)
- [ ] CLI command works: `etl update-schema`
- [ ] SimpleMySQLReplicator can read config: `etl run --tables patient --dry-run`
- [ ] Performance improved (measure query count)
- [ ] Documentation updated

---

## Rollback Procedure

If something breaks:

```bash
# 1. Revert code changes
git checkout main -- etl_pipeline/scripts/analyze_opendental_schema.py

# 2. Restore previous tables.yml if needed
cp logs/schema_analysis/backups/tables.yml.backup.<timestamp> etl_pipeline/config/tables.yml

# 3. Verify ETL works
etl run --tables patient --dry-run

# 4. Report issue
git diff main HEAD -- etl_pipeline/scripts/analyze_opendental_schema.py
```

---

## Contact Points for Issues

### If tables.yml Format Changes Break Things

**Affected**: `etl_pipeline/etl_pipeline/core/simple_mysql_replicator.py`  
**Methods**: `_load_configuration()`, `calculate_adaptive_batch_size()`, `get_extraction_strategy()`  
**Fix**: Ensure critical fields are preserved in `tables.yml`

### If CLI Command Fails

**Affected**: `etl_pipeline/etl_pipeline/cli/commands.py`  
**Method**: `update_schema()`  
**Fix**: Verify script path and subprocess execution

### If Tests Fail

**Affected**: All test files in `etl_pipeline/tests/.../analyze_opendental_schema/`  
**Fix**: Update test method calls to match refactored names

---

## Conclusion

**Refactoring is SAFE** because:

1. ‚úÖ **Loose Coupling**: Production code doesn't import analyzer methods
2. ‚úÖ **Data Interface**: Only `tables.yml` format matters
3. ‚úÖ **Isolated Tests**: Test failures are isolated, won't affect production
4. ‚úÖ **Backward Compatible**: Refactoring preserves `tables.yml` structure

**Key Takeaway**: As long as you preserve the critical fields in `tables.yml`, you can refactor the Python code freely!

---

**Last Updated**: 2025-01-17  
**Related Docs**:
- `docs/refactor_schema_analyzer_methods.md` - Refactoring plan
- `etl_pipeline/docs/DATA_FLOW_DIAGRAM.md` - Overall architecture

