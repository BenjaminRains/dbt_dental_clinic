--- analyze_opendental_schema.py
+++ analyze_opendental_schema_refactored.py
@@ -248,53 +248,40 @@
             logger.error(f"Failed to get schema for table {table_name}: {e}")
             return {'table_name': table_name, 'error': str(e)}
     
+    
+    def _query_table_metrics(self, table_name: str) -> dict:
+        """
+        Single source-of-truth query for per-table metrics, with per-run memoization.
+        Returns a dict with: row_count, data_length, index_length, total_size_bytes.
+        """
+        if table_name in self._metrics_cache:
+            return self._metrics_cache[table_name]
+        
+        with self.conn.cursor() as cur:
+            # information_schema.TABLES gives size info; COUNT(*) estimate via SHOW TABLE STATUS is faster in MySQL/MariaDB
+            cur.execute("""
+                SELECT
+                    TABLE_ROWS,
+                    DATA_LENGTH,
+                    INDEX_LENGTH
+                FROM information_schema.TABLES
+                WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
+            """, (self.database, table_name))
+            row = cur.fetchone()
+            if not row:
+                metrics = {'row_count': 0, 'data_length': 0, 'index_length': 0, 'total_size_bytes': 0}
+            else:
+                rc = int(row[0] or 0)
+                dl = int(row[1] or 0)
+                il = int(row[2] or 0)
+                metrics = {'row_count': rc, 'data_length': dl, 'index_length': il, 'total_size_bytes': dl + il}
+        
+        self._metrics_cache[table_name] = metrics
+        return metrics
+
     def get_estimated_row_count(self, table_name: str) -> int:
-        """Get estimated row count using MySQL's TABLE_ROWS from information_schema.
-        
-        This method is much faster than COUNT(*) and avoids locking large tables.
-        TABLE_ROWS provides an estimate that is updated by MySQL's statistics.
-        If TABLE_ROWS is unavailable, falls back to size-based estimation.
-        """
-        def _get_estimated_count():
-            with create_connection_manager(self.source_engine) as conn_manager:
-                # Use TABLE_ROWS from information_schema for estimated count (much faster than COUNT(*))
-                estimated_count_result = conn_manager.execute_with_retry(f"""
-                    SELECT TABLE_ROWS 
-                    FROM information_schema.tables 
-                    WHERE table_schema = '{self.source_db}' 
-                    AND table_name = '{table_name}'
-                """)
-                estimated_count = estimated_count_result.scalar() if estimated_count_result else 0
-                
-                # Handle None values from database
-                if estimated_count is None:
-                    estimated_count = 0
-                
-                # If TABLE_ROWS is NULL or 0, try to get a rough estimate from table size
-                if not estimated_count:
-                    # Get table size and estimate rows based on average row size
-                    size_result = conn_manager.execute_with_retry(f"""
-                        SELECT 
-                            data_length,
-                            index_length,
-                            ROUND(((data_length + index_length) / 1024 / 1024), 2) AS size_mb
-                        FROM information_schema.tables 
-                        WHERE table_schema = '{self.source_db}' 
-                        AND table_name = '{table_name}'
-                    """)
-                    
-                    if size_result:
-                        row = size_result.fetchone()
-                        if row and row[0]:  # data_length exists
-                            data_length = row[0]
-                            # Estimate based on average row size of 1KB (conservative estimate)
-                            estimated_count = max(1, int(data_length / 1024))
-                        else:
-                            estimated_count = 0
-                    else:
-                        estimated_count = 0
-                
-                return estimated_count
+        metrics = self._query_table_metrics(table_name)
+        return metrics['row_count']
         
         try:
             result = run_with_timeout(_get_estimated_count, DB_TIMEOUT)
@@ -307,28 +294,13 @@
             logger.error(f"Failed to get estimated row count for table {table_name}: {e}")
             return 0
 
-    def get_table_size_info(self, table_name: str) -> Dict:
-        """Get table size and estimated row count information using existing ConnectionManager."""
-        def _get_size_info():
-            # Use the existing ConnectionManager for proper connection handling
-            with create_connection_manager(self.source_engine) as conn_manager:
-                # Get estimated row count (much faster than COUNT(*))
-                estimated_row_count = self.get_estimated_row_count(table_name)
-                
-                # Get table size (approximate)
-                size_result = conn_manager.execute_with_retry(f"""
-                    SELECT 
-                        ROUND(((data_length + index_length) / 1024 / 1024), 2) AS size_mb
-                    FROM information_schema.tables 
-                    WHERE table_schema = '{self.source_db}' 
-                    AND table_name = '{table_name}'
-                """)
-                size_mb = size_result.scalar() if size_result else 0
-                # Ensure size_mb is a number, not None
-                if size_mb is None:
-                    size_mb = 0.0
-                
-                return {
+    def get_table_size_info(self, table_name: str) -> dict:
+        metrics = self._query_table_metrics(table_name)
+        return {
+            'data_length': metrics['data_length'],
+            'index_length': metrics['index_length'],
+            'total_size_bytes': metrics['total_size_bytes'],
+        }
                     'table_name': table_name,
                     'estimated_row_count': estimated_row_count,
                     'size_mb': size_mb,
@@ -691,7 +663,7 @@
         logger.debug(f"Selected primary incremental column '{selected_column}' as fallback (no priority columns found)")
         return selected_column
     
-    def analyze_table_performance_characteristics(self, table_name: str, schema_info: Dict, size_info: Dict) -> Dict:
+    def get_table_performance_profile(self, table_name: str, schema_info: Dict, size_info: Dict) -> Dict:
         """
         Analyze table characteristics for performance optimization.
         
@@ -843,7 +815,7 @@
         
         return int(total_memory_mb)
     
-    def enhanced_determine_extraction_strategy(self, table_name: str, schema_info: Dict, 
+    def determine_extraction_strategy(self, table_name: str, schema_info: Dict, 
                                              size_info: Dict, performance_chars: Dict) -> str:
         """
         Enhanced extraction strategy determination with performance considerations.
@@ -1209,10 +1181,10 @@
                             continue
                         
                         # Enhanced performance-based analysis
-                        performance_chars = self.analyze_table_performance_characteristics(table_name, schema_info, size_info)
+                        performance_chars = self.get_table_performance_profile(table_name, schema_info, size_info)
                         
                         # Determine extraction strategy using enhanced method
-                        extraction_strategy = self.enhanced_determine_extraction_strategy(table_name, schema_info, size_info, performance_chars)
+                        extraction_strategy = self.determine_extraction_strategy(table_name, schema_info, size_info, performance_chars)
                         
                         # Validate extraction strategy
                         if not self._validate_extraction_strategy(extraction_strategy):